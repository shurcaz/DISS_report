\subsection{Implementation Challenges}
The first implementation iteration suffered from several initially unforeseen problems that required in-depth analysis and modifications to the system. These issues resulted in the system either being unable to find a solution, requiring more powerful hardware, or taking so long to find a solution that testing was not feasible.

\subsubsection{Memory Usage}
The implemented data structure relied on a dictionary with positions serving as keys, storing only essential information, and facilitating straightforward modifications to internal logic and computations. However, during development, when testing configurations with a larger number of modules, the system encountered memory issues, halting the search prematurely despite having ample memory (24 GB). Upon investigation, it was discovered that the in-built copy module \ref{van1995python} in Python not only replicated objects but also copied referenced objects within the object, leading to a duplication of the entire search tree with each transition. This oversight stemmed from a lack of familiarity with Python's memory management mechanisms. Subsequently, the development of a custom duplication method for the class significantly reduced memory usage and improved the efficiency of the search algorithm by 90\%, enhancing the capabilities of the logic layer.

\subsubsection{Repeated Computations}
During an analysis of the system's performance, the \textbf{"GenNewStates()"} function (Seen in listing \ref{generateStatesPseudo}) emerged as one of the slowest processes. This function inserts states into a priority queue using a custom comparison function, which involves calculating multiple measurements for each state to determine priority. Initially, the linear search used to find the insertion index was suspected to be the bottleneck. However, after implementing a more efficient binary search algorithm, the expected improvement in insertion time was not fully realized.
\\\\
Further analysis showed that when inserting a state, if there were many states in the queue, the inserting state would undergo many comparisons to find the insertion index required to maintain priority order. Each time the inserted state is compared against another state, it would calculate its own measurement values and ask the other state to also calculate its measurement values. As these measurement values are based on their module layout, composition, and the goal state, all of which does not change during runtime, there was no need to be repeating calculations. 
\\\\
To address this issue, we optimized the process by saving measurement values upon calculation for each state and recalculating them only when necessary or when the goal state changed. This approach, coupled with the implementation of a binary search, significantly reduced the overall number of calculations required during insertion, improving the efficiency of the system.

\subsubsection{Optimising Python}
The greatest overall roadblock to further success and experimentation simply came down to the speed of the system and identifying slow processes. Due to the nature of the python programming language, often a considerable time-wasting process was a simple function that unknowingly had large overheads involved. The most successful method of improving the speed of the system during development was writing custom functions that utilise libraries built to utilise the C programming language. While there was no issue writing the custom utility functions, identifying where custom functions needed to be implemented took up most of the dedicated development time.